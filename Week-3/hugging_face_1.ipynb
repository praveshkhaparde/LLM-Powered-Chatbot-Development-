{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2882863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafe5506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\") ## pipeline object, with a task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a675f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b5fef85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78539dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9997857213020325}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"Wow, this is really bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9e1e4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline does 3 tasks:\n",
    "## - Preprocessing (Tokenising)\n",
    "## - Feed the tokens to the model\n",
    "## - Post Processing, shows the result in the suitable manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fa4cc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model = 'distilgpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51d80db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    }
   ],
   "source": [
    "res = generator(\n",
    "    \"In this course, we will teach you how to\",\n",
    "    max_length = 30, \n",
    "    num_return_sequences = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5897f077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'In this course, we will teach you how to get started with a simple, easy and easy way to start your own company.\\n\\n\\n\\n\\nStep 1: Create a new company on LinkedIn\\n1. Create a new company on LinkedIn\\n2. Create a new company on LinkedIn\\n3. Create a new company on LinkedIn\\n4. Create a new company on LinkedIn\\n5. Create a new company on LinkedIn\\n6. Create a new company on LinkedIn\\n7. Create a new company on LinkedIn\\n8. Create a new company on LinkedIn\\n9. Create a new company on LinkedIn\\n10. Create a new company on LinkedIn\\n11. Create a new company on LinkedIn\\n12. Create a new company on LinkedIn\\n13. Create a new company on LinkedIn\\n14. Create a new company on LinkedIn\\n15. Create a new company on LinkedIn\\n16. Create a new company on LinkedIn\\n17. Create a new company on LinkedIn\\n18. Create a new company on LinkedIn\\n19. Create a new company on LinkedIn\\n20. Create a new company on LinkedIn\\n21. Create an old company on LinkedIn\\n22. Create a new company on LinkedIn\\n23. Create a new company on LinkedIn\\n24. Create a new company on LinkedIn\\n25. Create a new company on LinkedIn\\n'}, {'generated_text': 'In this course, we will teach you how to write a blog entry about the project:\\n\\n\\n\\n\\nWe will write a blog post about the project:\\nWe will teach you how to write a blog entry about the project:\\nWe will teach you how to write a blog post about the project:\\nWe will teach you how to write a blog post about the project:\\nWe will teach you how to write a blog post about the project:\\nWe will teach you how to write a blog post about the project:\\nWe will teach you how to write a blog post about the project:\\nWe will teach you how to write a blog post about the project:\\nIf you like our blog post, you can sign up for our newsletter here.'}]\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cffed9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('zero-shot-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36d4ebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = classifier(\n",
    "    'This is a course about Python list comprehension', \n",
    "    candidate_labels = ['education', 'politics', 'business']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30cf0a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about Python list comprehension',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.9622026085853577, 0.026841355487704277, 0.010955985635519028]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f93c426",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
