## Week‑3

This directory contains notebooks exploring pre-trained transformer models, tokenizers, and Hugging Face pipelines (primarily sentiment classifiers, plus attempts at generative and zero-shot transformers):

- [`hugging_face_1.ipynb`](hugging_face_1.ipynb)  
- [`hugging_face_transformer2.ipynb`](hugging_face_transformer2.ipynb)

**Key milestone:**  
An **LSTM-based movie review sentiment classifier** using pre-trained transformer embeddings from the `google/bert_uncased_L-2_H-128_A-2` model:

- Notebook: [`Transformer_embedded_lstm_iter3(final).ipynb`](Transformer_embedded_lstm_iter3(final).ipynb)  
- Dataset: [News Category Dataset](https://www.kaggle.com/datasets/rmisra/news-category-dataset)  
- Results: **Train Accuracy: 85.11 %**, **Test Accuracy: 84.33 %** — demonstrating real learning, not overfitting  
