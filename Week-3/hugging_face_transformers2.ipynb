{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44f8b2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28415059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd0e3fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "282a7360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis', model = model, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79de17d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b59f287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9ad65cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_seq = \"Stay humble, eh.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1512583f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2994, 15716, 1010, 15501, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(text_seq) ## 0 means attention block should ignore this token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76260061",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 101 is begining of sentence, 102 is end of sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "374ab83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stay', 'humble', ',', 'eh', '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(text_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff708c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize(text_seq)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "885dc40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2994, 15716, 1010, 15501, 1012]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6c37d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stay humble, eh.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids) ## returns a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e17a066e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9978874325752258}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(text_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25feb8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stay',\n",
       " 'humble',\n",
       " ',',\n",
       " 'you',\n",
       " 'arrogant',\n",
       " 'boy',\n",
       " 'wow',\n",
       " ',',\n",
       " 'this',\n",
       " 'is',\n",
       " 'horrible']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize([\"Stay humble, you arrogant boy\", \"Wow, this is horrible\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d391399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9948498606681824},\n",
       " {'label': 'NEGATIVE', 'score': 0.998908281326294}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\"you arrogant boy\", \"Wow, this is horrible\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31eea5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_seq = \"Lionel is the king\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c6ca6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize(text_seq)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5468976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lionel is the king'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6691003e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14377, 2003, 1996, 2332]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "400c967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_seq = \"Raahfsasasfda is the king\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6bd8dfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize(text_seq)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7cab2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ra', '##ah', '##fs', '##asa', '##sf', '##da', 'is', 'the', 'king']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "116f2566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'raahfsasasfda is the king'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a797e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10958, 4430, 10343, 16782, 22747, 2850, 2003, 1996, 2332]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e07a2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd4b8a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trian = [\"I've been waiting for a HuggingFace course my whole life.\", \n",
    "           \"Python is great!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b66c772",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = classifier(X_trian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc131e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
       " {'label': 'POSITIVE', 'score': 0.9998615980148315}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "936f6699",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = tokenizer(X_trian, padding = True, truncation=True, \n",
    "                  max_length = 32, return_tensors = 'pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "091e154a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
       "          2607,  2026,  2878,  2166,  1012,   102],\n",
       "        [  101, 18750,  2003,  2307,   999,   102,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9453e877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-1.5607,  1.6123],\n",
      "        [-4.2745,  4.6111]]), hidden_states=None, attentions=None)\n",
      "tensor([[4.0195e-02, 9.5980e-01],\n",
      "        [1.3835e-04, 9.9986e-01]])\n",
      "tensor([1, 1])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**batch)\n",
    "    print(outputs)\n",
    "    predictions = F.softmax(outputs.logits, dim = 1)\n",
    "    print(predictions)\n",
    "    labels = torch.argmax(predictions, dim = 1)\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50259fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = \"saved\"\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "model.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90c7d043",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = AutoTokenizer.from_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "925de14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = AutoTokenizer.from_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6b9e308",
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://www.youtube.com/watch?v=QEaBAZQCtwE\n",
    "## 13 min timestamp to understand how to train\n",
    "## a pytorch model more easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f34eba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
