{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f9dd464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('100_Unique_QA_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26d59fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the capital of Germany?</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
       "      <td>Harper-Lee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the largest planet in our solar system?</td>\n",
       "      <td>Jupiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the boiling point of water in Celsius?</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          question      answer\n",
       "0                   What is the capital of France?       Paris\n",
       "1                  What is the capital of Germany?      Berlin\n",
       "2               Who wrote 'To Kill a Mockingbird'?  Harper-Lee\n",
       "3  What is the largest planet in our solar system?     Jupiter\n",
       "4   What is the boiling point of water in Celsius?         100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0061bb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tokenising the dataset (using split)\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('?', '')\n",
    "    text = text.replace(\"'\", '')\n",
    "    return text.split() ## Default Param is space for split!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4ec8094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is', 'alcaraz', 'better', 'than', 'sinner']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize('Is Alcaraz better than Sinner?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbeaa2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'?'.replace('?', '') ## not in-place!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f591c192",
   "metadata": {},
   "outputs": [],
   "source": [
    "## forming the vocabulary\n",
    "vocab = {'<UNK>' : 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "471d5ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(row):\n",
    "    tokenized_q = tokenize(row['question'])\n",
    "    tokenized_ans = tokenize(row['answer'])\n",
    "    tokens = tokenized_q + tokenized_ans\n",
    "    for token in tokens:\n",
    "        if token not in vocab:\n",
    "            vocab[token] = len(vocab)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c02b03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "      ... \n",
       "85    None\n",
       "86    None\n",
       "87    None\n",
       "88    None\n",
       "89    None\n",
       "Length: 90, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(build_vocab, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81fff49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c743c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## words -> numerical indices\n",
    "def text_to_indices(text, vocab):\n",
    "    indexed_text = []\n",
    "    for token in tokenize(text):\n",
    "        if token in vocab:\n",
    "            indexed_text.append(vocab[token])\n",
    "        else:\n",
    "            indexed_text.append(vocab['<UNK>'])\n",
    "    return indexed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6da34b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_indices('What is CampusX?', vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1effc1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6282dd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(Dataset):\n",
    "    def __init__(self, df, vocab):\n",
    "        self.df = df\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        question_num = text_to_indices(self.df.iloc[index]['question'], self.vocab)\n",
    "        ans_num = text_to_indices(self.df.iloc[index]['answer'], self.vocab)\n",
    "        return torch.tensor(question_num), torch.tensor(ans_num).squeeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e6950236",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = QADataset(df, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8533d139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1,  2,  3,  4,  5, 53]), tensor(54))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6074b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae502edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 10,  29, 130, 131]]) tensor([132])\n",
      "tensor([[ 10,  75, 111]]) tensor([112])\n",
      "tensor([[10,  2,  3, 66,  5, 67]]) tensor([68])\n",
      "tensor([[  1,   2,   3,   4,   5, 286]]) tensor([287])\n",
      "tensor([[  1,   2,   3,  33,  34,   5, 245]]) tensor([246])\n",
      "tensor([[ 10,  11, 189, 158, 190]]) tensor([191])\n",
      "tensor([[ 42, 216, 118, 217, 218,  19,  14, 219,  43]]) tensor([220])\n",
      "tensor([[ 42, 200,   2,  14, 201, 202, 203, 204]]) tensor([205])\n",
      "tensor([[  1,   2,   3,  37,  38,  39, 161]]) tensor([162])\n",
      "tensor([[ 42, 107,   2, 108,  19, 109]]) tensor([110])\n",
      "tensor([[ 78,  79, 288,  81,  19,  14, 289]]) tensor([85])\n",
      "tensor([[78, 79, 80, 81, 82, 83, 84]]) tensor([85])\n",
      "tensor([[10, 55,  3, 56,  5, 57]]) tensor([58])\n",
      "tensor([[ 42, 101,   2,   3,  17]]) tensor([102])\n",
      "tensor([[42, 86, 87, 88, 89, 39, 90]]) tensor([91])\n",
      "tensor([[ 42, 174,   2,  62,  39, 175, 176,  12, 177, 178]]) tensor([179])\n",
      "tensor([[  1,   2,   3, 234,   5, 235]]) tensor([131])\n",
      "tensor([[ 78,  79, 195,  81,  19,   3, 196, 197, 198]]) tensor([199])\n",
      "tensor([[  1,   2,   3, 212,   5,  14, 213, 214]]) tensor([215])\n",
      "tensor([[ 10, 308,   3, 309, 310]]) tensor([311])\n",
      "tensor([[ 10, 140,   3, 141, 270,  93, 271,   5,   3, 272]]) tensor([273])\n",
      "tensor([[  1,   2,   3, 180, 181, 182, 183]]) tensor([184])\n",
      "tensor([[ 42,   2,   3, 210, 137, 168, 211, 169]]) tensor([113])\n",
      "tensor([[10, 96,  3, 97]]) tensor([98])\n",
      "tensor([[  1,   2,   3, 163, 164, 165,  83,  84]]) tensor([166])\n",
      "tensor([[ 42, 255,   2, 256,  83, 257, 258]]) tensor([259])\n",
      "tensor([[  1,   2,   3, 146,  86,  19, 192, 193]]) tensor([194])\n",
      "tensor([[  1,   2,   3,   4,   5, 206]]) tensor([207])\n",
      "tensor([[  1,   2,   3,  37, 133,   5,  26]]) tensor([134])\n",
      "tensor([[ 42,   2,   3, 274, 211, 275]]) tensor([276])\n",
      "tensor([[ 10, 140,   3, 141, 171,   5,   3,  70, 172]]) tensor([173])\n",
      "tensor([[ 42, 263, 264,  14, 265, 266, 158, 267]]) tensor([268])\n",
      "tensor([[ 1,  2,  3,  4,  5, 53]]) tensor([54])\n",
      "tensor([[ 42, 290, 291, 118, 292, 158, 293, 294]]) tensor([295])\n",
      "tensor([[ 1,  2,  3, 33, 34,  5, 35]]) tensor([36])\n",
      "tensor([[ 42, 137,   2, 138,  39, 139]]) tensor([53])\n",
      "tensor([[ 1,  2,  3, 69,  5,  3, 70, 71]]) tensor([72])\n",
      "tensor([[ 1,  2,  3,  4,  5, 99]]) tensor([100])\n",
      "tensor([[  1,   2,   3, 221,   5, 222, 223, 224]]) tensor([225])\n",
      "tensor([[  1,   2,   3, 122, 123,  19,   3,  45]]) tensor([124])\n",
      "tensor([[ 42, 117, 118,   3, 119,  94, 120]]) tensor([121])\n",
      "tensor([[ 42, 137, 118,   3, 247,   5, 248]]) tensor([249])\n",
      "tensor([[1, 2, 3, 4, 5, 8]]) tensor([9])\n",
      "tensor([[ 10, 140,   3, 141, 142,  12, 143,  83,   3, 144]]) tensor([145])\n",
      "tensor([[ 42, 137,   2, 138,  39, 175, 269]]) tensor([99])\n",
      "tensor([[  1,   2,   3,   4,   5, 109]]) tensor([317])\n",
      "tensor([[ 10,   2,  62,  63,   3, 283,   5, 284]]) tensor([285])\n",
      "tensor([[ 1,  2,  3, 50, 51, 19,  3, 45]]) tensor([52])\n",
      "tensor([[ 10,  75, 208]]) tensor([209])\n",
      "tensor([[  1,   2,   3, 141, 117,  83,   3, 277, 278]]) tensor([121])\n",
      "tensor([[ 10,  75,   3, 296,  19, 297]]) tensor([298])\n",
      "tensor([[ 78,  79, 150, 151,  14, 152, 153]]) tensor([154])\n",
      "tensor([[  1,   2,   3,  17, 115,  83,  84]]) tensor([116])\n",
      "tensor([[  1,   2,   3,   4,   5, 113]]) tensor([114])\n",
      "tensor([[ 42, 137,   2,  62,  39,   3, 322, 323]]) tensor([6])\n",
      "tensor([[10, 11, 12, 13, 14, 15]]) tensor([16])\n",
      "tensor([[ 42, 125,   2,  62,  63,   3, 126, 127]]) tensor([128])\n",
      "tensor([[ 1,  2,  3, 92, 93, 94]]) tensor([95])\n",
      "tensor([[  1,   2,   3, 103,   5, 104,  19, 105]]) tensor([106])\n",
      "tensor([[  1,   2,   3,   4,   5, 236, 237]]) tensor([238])\n",
      "tensor([[ 42,  18, 118,   3, 186, 187]]) tensor([188])\n",
      "tensor([[ 42, 299, 300, 118,  14, 301, 302, 158, 303, 304, 305, 306]]) tensor([307])\n",
      "tensor([[  1,   2,   3,   4,   5, 135]]) tensor([136])\n",
      "tensor([[42, 18,  2, 62, 63,  3, 64, 18]]) tensor([65])\n",
      "tensor([[ 10,  11, 157, 158, 159]]) tensor([160])\n",
      "tensor([[ 1,  2,  3, 17, 18, 19, 20, 21, 22]]) tensor([23])\n",
      "tensor([[ 1,  2,  3,  4,  5, 73]]) tensor([74])\n",
      "tensor([[10, 29,  3, 30, 31]]) tensor([32])\n",
      "tensor([[ 42, 250, 251, 118, 252, 253]]) tensor([254])\n",
      "tensor([[1, 2, 3, 4, 5, 6]]) tensor([7])\n",
      "tensor([[42, 43, 44, 45, 46, 47, 48]]) tensor([49])\n",
      "tensor([[  1,   2,   3,   4,   5, 279]]) tensor([280])\n",
      "tensor([[ 1,  2,  3, 24, 25,  5, 26, 19, 27]]) tensor([28])\n",
      "tensor([[ 78,  79, 129,  81,  19,   3,  21,  22]]) tensor([36])\n",
      "tensor([[  1,   2,   3,  92, 137,  19,   3,  45]]) tensor([185])\n",
      "tensor([[ 10,  96,   3, 104, 239]]) tensor([240])\n",
      "tensor([[  1,   2,   3, 146, 147,  19, 148]]) tensor([149])\n",
      "tensor([[  1,   2,   3,  69,   5, 155]]) tensor([156])\n",
      "tensor([[ 42, 312,   2, 313,  62,  63,   3, 314, 315]]) tensor([316])\n",
      "tensor([[ 42, 318,   2,  62,  63,   3, 319,   5, 320]]) tensor([321])\n",
      "tensor([[ 42, 167,   2,   3,  17, 168, 169]]) tensor([170])\n",
      "tensor([[  1,  87, 229, 230, 231, 232]]) tensor([233])\n",
      "tensor([[ 1,  2,  3, 59, 25,  5, 26, 19, 60]]) tensor([61])\n",
      "tensor([[ 1,  2,  3, 69,  5, 53]]) tensor([260])\n",
      "tensor([[ 42,  86,  87, 241, 242,  19,  39, 243]]) tensor([244])\n",
      "tensor([[10, 75, 76]]) tensor([77])\n",
      "tensor([[ 42,  18,   2,   3, 281,  12,   3, 282]]) tensor([205])\n",
      "tensor([[ 42, 137,   2, 226,  12,   3, 227, 228]]) tensor([155])\n",
      "tensor([[ 1,  2,  3, 37, 38, 39, 40]]) tensor([41])\n",
      "tensor([[ 78,  79, 261, 151,  14, 262, 153]]) tensor([36])\n"
     ]
    }
   ],
   "source": [
    "for question, ans in dataloader:\n",
    "    print(question, ans) ## notice that dim of each q is 2!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "da8e4b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1c193c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, embedding_dim=50)\n",
    "        self.rnn = nn.RNN(50, 64)\n",
    "        self.fc = nn.Linear(64, vocab_size)\n",
    "\n",
    "    def forward(self, q):\n",
    "        embed_q = self.emb(q)\n",
    "        hidden, final = self.rnn(embed_q)\n",
    "        output = self.fc(final)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b2fd1aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "51a7ca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nn.Embedding(324, embedding_dim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "35d44b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x(dataset[0][1]).shape ## Every word converted to a 50 dim vector!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2fe5accb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x(dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "cd69decd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 50])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "85520852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 50])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ebac99df",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = nn.RNN(50, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1fc961ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7.0196e-01, -6.9564e-01, -3.6728e-01,  6.5588e-01, -3.5761e-01,\n",
       "           2.5379e-01, -2.9545e-01,  8.4917e-02, -3.8642e-02,  5.1495e-01,\n",
       "           2.6000e-01,  4.6536e-01, -6.0811e-01, -3.7547e-01,  2.6443e-01,\n",
       "           3.7483e-02,  1.8018e-01, -1.0811e-01,  1.6788e-01,  2.5754e-01,\n",
       "           2.2548e-01, -3.5617e-01, -3.9842e-01, -3.7144e-01, -2.4607e-01,\n",
       "           2.7526e-01,  5.0866e-01,  5.6276e-01,  7.6535e-02,  9.1755e-02,\n",
       "           2.2196e-01,  5.1086e-01, -6.6129e-01,  7.8560e-03,  5.8002e-01,\n",
       "           2.7302e-01, -3.7445e-01, -6.3570e-02,  1.7417e-01,  2.4752e-01,\n",
       "          -1.3555e-01, -5.2452e-02,  5.5346e-01, -6.6101e-01,  4.2013e-01,\n",
       "           4.2597e-01,  2.1429e-01,  6.3348e-01, -4.7691e-01,  7.6595e-02,\n",
       "           1.8219e-01,  1.4340e-01, -4.8715e-02,  2.7063e-01,  1.4113e-01,\n",
       "           1.9320e-01,  4.5166e-01,  9.6882e-03,  5.6700e-01,  4.0551e-01,\n",
       "          -3.2973e-01,  2.2357e-01, -2.9693e-01,  3.3199e-01],\n",
       "         [-7.4074e-03,  2.1195e-01,  5.7726e-01, -6.4927e-01, -3.2815e-01,\n",
       "           3.8609e-01,  5.2852e-01, -6.4915e-01,  6.1858e-02,  1.9314e-02,\n",
       "           5.2703e-01, -5.7594e-01, -3.2319e-01, -8.4388e-01, -6.8585e-01,\n",
       "           7.4916e-01,  3.3289e-01,  3.2819e-01, -5.0020e-03, -2.2569e-01,\n",
       "          -4.8515e-01,  5.8222e-01, -1.3895e-01, -4.2690e-01,  1.6437e-01,\n",
       "           2.4667e-02,  6.2039e-01,  2.7065e-01, -4.7725e-02,  6.1314e-01,\n",
       "          -8.0872e-01,  7.7196e-01, -2.6198e-01,  1.0953e-01, -4.8728e-01,\n",
       "          -5.7739e-01, -6.8087e-01,  2.0530e-01, -6.3266e-01, -4.2180e-01,\n",
       "           6.9668e-01,  6.9116e-01, -2.3656e-01, -1.8490e-01, -6.5588e-01,\n",
       "           2.4835e-01, -9.0061e-02, -1.4420e-01,  1.3454e-01, -1.4276e-01,\n",
       "          -4.1997e-02, -1.6536e-01,  8.8062e-01,  2.7100e-01, -6.1514e-01,\n",
       "          -1.8873e-01,  1.5782e-01,  2.4665e-01,  2.9972e-01, -3.6697e-01,\n",
       "          -2.5202e-01, -3.8117e-01, -3.7197e-02, -5.3948e-01],\n",
       "         [ 1.9602e-01, -1.4361e-01, -5.6553e-01,  4.9958e-01,  3.8241e-01,\n",
       "           4.7982e-01,  7.6266e-01,  1.0298e-01,  4.8938e-01,  7.0100e-01,\n",
       "           8.8267e-01, -5.4158e-01, -6.5618e-01,  2.2384e-01,  2.6597e-01,\n",
       "           8.0432e-01, -4.9087e-02,  6.0946e-01,  2.9283e-01, -3.4596e-01,\n",
       "          -9.2813e-01, -2.5183e-01,  5.0867e-01,  3.4071e-01,  3.1111e-02,\n",
       "           1.9565e-01, -5.6388e-01,  5.8079e-01,  1.8355e-01, -3.8232e-01,\n",
       "          -5.1646e-01,  3.6984e-01, -3.6767e-02, -5.0711e-01,  4.3017e-04,\n",
       "           7.4533e-01, -2.8688e-01, -4.0229e-01, -5.0278e-02,  7.0901e-01,\n",
       "          -4.1772e-01, -8.0198e-01,  4.9556e-01, -5.9773e-01, -2.4662e-01,\n",
       "          -5.9928e-01, -3.7656e-01,  6.2153e-01, -2.3441e-01,  5.9470e-01,\n",
       "          -6.5840e-01,  2.1894e-03,  3.3191e-02,  8.6225e-01,  1.7228e-01,\n",
       "          -1.7118e-01,  4.9091e-03,  5.8491e-02,  1.5314e-01, -4.0424e-01,\n",
       "           7.4113e-01, -6.7208e-01,  3.5806e-01, -5.8888e-01],\n",
       "         [-4.6597e-01,  3.5834e-01,  6.7223e-01, -5.7144e-01,  4.7787e-01,\n",
       "           9.7499e-02,  8.2580e-01, -7.0054e-01,  7.7366e-01, -3.2600e-01,\n",
       "           8.1886e-01, -3.5129e-01,  2.5504e-01, -5.5649e-02,  3.7939e-01,\n",
       "           6.6086e-01,  2.0270e-01,  6.0043e-01,  2.6231e-01, -3.8289e-01,\n",
       "          -3.4333e-01, -6.7158e-01,  3.0522e-01,  1.2910e-01,  1.2231e-01,\n",
       "           6.6556e-01,  3.2143e-01,  3.8546e-02,  3.4111e-01,  7.0558e-02,\n",
       "          -7.1943e-01,  5.2735e-01, -5.1091e-01, -4.4198e-02, -9.7239e-02,\n",
       "          -1.6916e-01, -4.3037e-01, -4.1142e-01, -6.1654e-01, -2.3543e-01,\n",
       "           3.9998e-01, -6.0376e-01, -5.1101e-01,  2.7470e-01, -4.3179e-01,\n",
       "          -5.7393e-01, -7.1819e-01,  2.8430e-01,  6.2838e-01,  2.1604e-01,\n",
       "           4.2736e-01,  6.1324e-01,  8.5230e-01,  6.0893e-01,  7.4555e-01,\n",
       "          -7.2637e-01, -6.0419e-01, -1.9733e-01, -3.1649e-01, -5.5372e-01,\n",
       "           1.5953e-01, -4.5081e-01, -3.3825e-01,  4.1793e-03],\n",
       "         [-4.3559e-01, -7.4798e-01,  2.5187e-01, -2.1516e-01,  4.7282e-01,\n",
       "          -4.5060e-01,  4.6969e-01,  2.5610e-01, -8.1722e-01, -6.3822e-02,\n",
       "          -7.8340e-01, -4.6018e-01, -5.2859e-01, -6.2523e-01,  3.1703e-02,\n",
       "          -2.5718e-01,  1.7571e-01,  3.7417e-01, -2.4211e-01, -7.0548e-02,\n",
       "          -6.5061e-01,  5.6443e-02,  4.3039e-01,  5.7935e-02, -6.9486e-01,\n",
       "           7.3659e-01,  9.7148e-01,  2.2337e-01,  5.4142e-02, -9.4993e-01,\n",
       "           3.0849e-01, -1.0885e-01, -7.9807e-01, -8.3646e-01, -1.4122e-01,\n",
       "           8.5941e-01, -5.4037e-01,  5.6938e-01, -4.7511e-01,  3.9484e-01,\n",
       "           4.6081e-01,  3.0387e-01,  7.0480e-01,  8.6381e-02,  6.9168e-01,\n",
       "           8.3314e-01,  2.0274e-01, -7.4939e-01, -4.8192e-01, -3.6314e-01,\n",
       "          -2.8474e-01, -7.0147e-01, -1.0845e-01, -5.4460e-01,  3.2612e-02,\n",
       "           1.9462e-02,  4.1617e-01, -6.8441e-01,  6.0722e-01, -4.8401e-01,\n",
       "           1.5528e-01,  5.0431e-01,  2.5087e-01, -3.9775e-01],\n",
       "         [-6.2434e-02, -5.8650e-01,  3.6218e-01, -2.9653e-01, -7.0127e-01,\n",
       "          -6.6091e-01, -1.7274e-01, -2.5646e-01,  8.6749e-01, -3.1050e-01,\n",
       "           4.1635e-01, -3.3249e-01, -2.8075e-01, -8.5222e-02, -7.8828e-01,\n",
       "           8.0675e-01,  9.4868e-01,  7.3319e-02, -3.8823e-01, -4.3710e-01,\n",
       "          -1.2880e-01,  2.4953e-01,  1.0012e-01, -8.3271e-01,  8.0111e-01,\n",
       "          -8.3586e-01,  2.4056e-01,  3.5500e-01,  1.9481e-01,  2.7907e-01,\n",
       "          -6.7042e-01, -9.4978e-02,  1.9731e-01,  9.1715e-01, -3.2311e-01,\n",
       "          -1.2368e-01,  3.8231e-01, -8.3013e-01, -9.0169e-01,  2.2946e-01,\n",
       "          -6.6940e-01,  2.5367e-01, -2.4262e-01, -1.4067e-01, -6.0694e-01,\n",
       "          -1.6438e-01, -6.5455e-01,  7.9493e-01, -1.4682e-01,  6.5265e-01,\n",
       "          -7.5523e-01,  5.7243e-01,  2.2516e-02,  5.8569e-01, -2.1680e-02,\n",
       "           1.3637e-02,  7.9116e-01,  6.6417e-01, -6.9271e-01,  4.1954e-01,\n",
       "          -6.3911e-01, -3.4500e-01, -2.6135e-01, -2.5550e-01]],\n",
       "        grad_fn=<SqueezeBackward1>),\n",
       " tensor([[-0.0624, -0.5865,  0.3622, -0.2965, -0.7013, -0.6609, -0.1727, -0.2565,\n",
       "           0.8675, -0.3105,  0.4163, -0.3325, -0.2808, -0.0852, -0.7883,  0.8067,\n",
       "           0.9487,  0.0733, -0.3882, -0.4371, -0.1288,  0.2495,  0.1001, -0.8327,\n",
       "           0.8011, -0.8359,  0.2406,  0.3550,  0.1948,  0.2791, -0.6704, -0.0950,\n",
       "           0.1973,  0.9171, -0.3231, -0.1237,  0.3823, -0.8301, -0.9017,  0.2295,\n",
       "          -0.6694,  0.2537, -0.2426, -0.1407, -0.6069, -0.1644, -0.6546,  0.7949,\n",
       "          -0.1468,  0.6526, -0.7552,  0.5724,  0.0225,  0.5857, -0.0217,  0.0136,\n",
       "           0.7912,  0.6642, -0.6927,  0.4195, -0.6391, -0.3450, -0.2613, -0.2555]],\n",
       "        grad_fn=<SqueezeBackward1>))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y(a) ## A tuple! That's why we can't use Sequential!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "87b95d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 64])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y(a)[0].shape ## All hidden outputs(hidden states) stacked together! o1-o6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d1ace79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y(a)[1].shape ## Final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "df32a55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = y(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a05206e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = nn.Linear(64, 324)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "786131c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 324])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z(t[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0d412af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7c2f9308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.one_hot(torch.tensor([1]), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "846e09e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleRNN(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8d927cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "206e403d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss = 524.390729\n",
      "Epoch: 2, Loss = 460.442861\n",
      "Epoch: 3, Loss = 383.409234\n",
      "Epoch: 4, Loss = 318.014286\n",
      "Epoch: 5, Loss = 264.671083\n",
      "Epoch: 6, Loss = 216.002807\n",
      "Epoch: 7, Loss = 170.529908\n",
      "Epoch: 8, Loss = 132.718000\n",
      "Epoch: 9, Loss = 101.663375\n",
      "Epoch: 10, Loss = 78.004884\n",
      "Epoch: 11, Loss = 59.742183\n",
      "Epoch: 12, Loss = 46.410664\n",
      "Epoch: 13, Loss = 36.689010\n",
      "Epoch: 14, Loss = 29.633395\n",
      "Epoch: 15, Loss = 24.232887\n",
      "Epoch: 16, Loss = 20.165634\n",
      "Epoch: 17, Loss = 16.951263\n",
      "Epoch: 18, Loss = 14.384564\n",
      "Epoch: 19, Loss = 12.323876\n",
      "Epoch: 20, Loss = 10.709019\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for q, a in dataloader:\n",
    "        # print(q)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(q.squeeze(0)).squeeze(0)\n",
    "        # print(out.shape)\n",
    "        # print(nn.functional.one_hot(a[0], len(vocab)).shape)\n",
    "        loss = loss_fn(out, nn.functional.one_hot(a[0], len(vocab)).to(torch.float64))\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    print(f'Epoch: {epoch + 1}, Loss = {total_loss:4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "131e9a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, question, threshold = 0.5):\n",
    "    numerical_q = text_to_indices(question, vocab)\n",
    "    q_tensor = torch.tensor(numerical_q)\n",
    "    with torch.no_grad():\n",
    "        output = model(q_tensor)\n",
    "    output = nn.functional.softmax(output, dim = 1)\n",
    "    val, ind = torch.max(output, dim = 1)\n",
    "    if val < threshold:\n",
    "        print('Idk')\n",
    "    else:\n",
    "        return list(vocab.keys())[ind]\n",
    "    # print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e91907f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(23)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(model(dataset[3][0]).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7e59a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = predict(model , 'Capital of Germany?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9bb6849f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'berlin'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c6046f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question    Who wrote 'To Kill a Mockingbird'?\n",
       "answer                              Harper-Lee\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6adad3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'harper-lee'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vocab.keys())[ans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d61d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
