{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFuIDwYWFQkH"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Library Installation"
      ],
      "metadata": {
        "id": "VL3232TuGFRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q youtube-transcript-api langchain-community langchain-openai \\ faiss-cpu tiktoken python-dotenv"
      ],
      "metadata": {
        "id": "0xdlekJpGGxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "_O6Y_xUzGSIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Indexing Step-1: Document Ingestion"
      ],
      "metadata": {
        "id": "5diUb2PcGtX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_id = \"Gfr50f6ZBvo\" ## only ID, not entire URL"
      ],
      "metadata": {
        "id": "C1pUuex5Gnar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  transcript_list = YouTubeTranscriptApi.get_transcript(video_id) ## returns best lang if languages arg left empty\n",
        "\n",
        "  # Flatten it to plain text\n",
        "  transcript = \" \".join(chunk['text'] for chunk in transcript_list)\n",
        "  print(transcript)\n",
        "except TranscriptsDisabled:\n",
        "  print(\"No transcript/captions available for this video\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V5cmZciPG46B",
        "outputId": "b9b6c40e-38a7-452f-bd2b-d7d5f79b17af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RequestBlocked",
          "evalue": "\nCould not retrieve a transcript for the video https://www.youtube.com/watch?v=Gfr50f6ZBvo! This is most likely caused by:\n\nYouTube is blocking requests from your IP. This usually is due to one of the following reasons:\n- You have done too many requests and your IP has been blocked by YouTube\n- You are doing requests from an IP belonging to a cloud provider (like AWS, Google Cloud Platform, Azure, etc.). Unfortunately, most IPs from cloud providers are blocked by YouTube.\n\nThere are two things you can do to work around this:\n1. Use proxies to hide your IP address, as explained in the \"Working around IP bans\" section of the README (https://github.com/jdepoix/youtube-transcript-api?tab=readme-ov-file#working-around-ip-bans-requestblocked-or-ipblocked-exception).\n2. (NOT RECOMMENDED) If you authenticate your requests using cookies, you will be able to continue doing requests for a while. However, YouTube will eventually permanently ban the account that you have used to authenticate with! So only do this if you don't mind your account being banned!\n\nIf you are sure that the described cause is not responsible for this error and that a transcript should be retrievable, please create an issue at https://github.com/jdepoix/youtube-transcript-api/issues. Please add which version of youtube_transcript_api you are using and provide the information needed to replicate the error. Also make sure that there are no open issues which already describe your problem!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRequestBlocked\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-7-3825142003.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtranscript_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYouTubeTranscriptApi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transcript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## returns best lang if languages arg left empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m# Flatten it to plain text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtranscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtranscript_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/youtube_transcript_api/_api.py\u001b[0m in \u001b[0;36mget_transcript\u001b[0;34m(cls, video_id, languages, proxies, preserve_formatting)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"`video_id` must be a string\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         return (\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_transcripts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mfind_transcript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreserve_formatting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreserve_formatting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/youtube_transcript_api/_api.py\u001b[0m in \u001b[0;36mlist_transcripts\u001b[0;34m(cls, video_id, proxies)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mproxy_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxy_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         )\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mytt_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/youtube_transcript_api/_api.py\u001b[0m in \u001b[0;36mlist\u001b[0;34m(self, video_id)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mMake\u001b[0m \u001b[0msure\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mthis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mactual\u001b[0m \u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNOT\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mURL\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;31m!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \"\"\"\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/youtube_transcript_api/_transcripts.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, video_id)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_http_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mvideo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_captions_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         )\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/youtube_transcript_api/_transcripts.py\u001b[0m in \u001b[0;36m_fetch_captions_json\u001b[0;34m(self, video_id, try_number)\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtry_number\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mretries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_captions_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_number\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtry_number\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_proxy_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_proxy_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_innertube_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/youtube_transcript_api/_transcripts.py\u001b[0m in \u001b[0;36m_fetch_captions_json\u001b[0;34m(self, video_id, try_number)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_innertube_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0minnertube_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_innertube_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_captions_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minnertube_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRequestBlocked\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             retries = (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/youtube_transcript_api/_transcripts.py\u001b[0m in \u001b[0;36m_extract_captions_json\u001b[0;34m(self, innertube_data, video_id)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_captions_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minnertube_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_playability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minnertube_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"playabilityStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         captions_json = innertube_data.get(\"captions\", {}).get(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/youtube_transcript_api/_transcripts.py\u001b[0m in \u001b[0;36m_assert_playability\u001b[0;34m(self, playability_status_data, video_id)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mplayability_status\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_PlayabilityStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOGIN_REQUIRED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_PlayabilityFailedReason\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBOT_DETECTED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRequestBlocked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_PlayabilityFailedReason\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAGE_RESTRICTED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mAgeRestricted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRequestBlocked\u001b[0m: \nCould not retrieve a transcript for the video https://www.youtube.com/watch?v=Gfr50f6ZBvo! This is most likely caused by:\n\nYouTube is blocking requests from your IP. This usually is due to one of the following reasons:\n- You have done too many requests and your IP has been blocked by YouTube\n- You are doing requests from an IP belonging to a cloud provider (like AWS, Google Cloud Platform, Azure, etc.). Unfortunately, most IPs from cloud providers are blocked by YouTube.\n\nThere are two things you can do to work around this:\n1. Use proxies to hide your IP address, as explained in the \"Working around IP bans\" section of the README (https://github.com/jdepoix/youtube-transcript-api?tab=readme-ov-file#working-around-ip-bans-requestblocked-or-ipblocked-exception).\n2. (NOT RECOMMENDED) If you authenticate your requests using cookies, you will be able to continue doing requests for a while. However, YouTube will eventually permanently ban the account that you have used to authenticate with! So only do this if you don't mind your account being banned!\n\nIf you are sure that the described cause is not responsible for this error and that a transcript should be retrievable, please create an issue at https://github.com/jdepoix/youtube-transcript-api/issues. Please add which version of youtube_transcript_api you are using and provide the information needed to replicate the error. Also make sure that there are no open issues which already describe your problem!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transcript_list.__len__()"
      ],
      "metadata": {
        "id": "w08U-kUDHVAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcript_list[0]\n",
        "## duration is the time for which the caption remains on the screen\n",
        "## all times in seconds"
      ],
      "metadata": {
        "id": "1ErLwU9gHXkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"transcript.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    transcript = file.read()"
      ],
      "metadata": {
        "id": "aPjcqOdA9HiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Indexing Step-2: Text-Splitting"
      ],
      "metadata": {
        "id": "dsv3ZxjdJXeH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)"
      ],
      "metadata": {
        "id": "m6rRNGzqHcvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = splitter.create_documents([transcript])"
      ],
      "metadata": {
        "id": "2v0q2NBBJqH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tl7cRtBKJvug",
        "outputId": "c1870126-e410-4692-e20c-886d0c24fa00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={}, page_content=\"the following is a conversation with demus hasabis ceo and co-founder of deepmind a company that has published and builds some of the most incredible artificial intelligence systems in the history of computing including alfred zero that learned all by itself to play the game of gold better than any human in the world and alpha fold two that solved protein folding both tasks considered nearly impossible for a very long time demus is widely considered to be one of the most brilliant and impactful humans in the history of artificial intelligence and science and engineering in general this was truly an honor and a pleasure for me to finally sit down with him for this conversation and i'm sure we will talk many times again in the future this is the lex friedman podcast to support it please check out our sponsors in the description and now dear friends here's demis hassabis let's start with a bit of a personal question am i an ai program you wrote to interview people until i get good enough\")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpbPaYNmJxOt",
        "outputId": "9b9dc995-50bc-4bf9-c2ca-df1d761889cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "168"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step-3 & 4: Embedding Generation and Storing in Vector Store"
      ],
      "metadata": {
        "id": "zzOfu3uoKDRB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eH3tHl_iMbu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings(model = 'text-embedding-3-small')\n",
        "vector_store = FAISS.from_documents(chunks[:10], embeddings)"
      ],
      "metadata": {
        "id": "rfzfXlabKCQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_core"
      ],
      "metadata": {
        "id": "v21vcAZKOlSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.documents.base import Document  # for types\n",
        "\n",
        "\n",
        "# Retry decorator for RateLimitError\n",
        "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
        "def embed_batch(texts: list[str]) -> list[list[float]]:\n",
        "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "    return embeddings.embed_documents(texts)\n",
        "\n",
        "def build_faiss_from_docs(documents: list[Document], batch_size: int = 32, rpm: int = 30):\n",
        "    # Split docs into chunks\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    chunks = splitter.split_documents(documents)\n",
        "\n",
        "    vector_store = None\n",
        "    interval = 60.0 / rpm\n",
        "\n",
        "    for i in range(0, len(chunks), batch_size):\n",
        "        batch = chunks[i : i + batch_size]\n",
        "        texts = [d.page_content for d in batch]\n",
        "        embs = embed_batch(texts)\n",
        "\n",
        "        if vector_store is None:\n",
        "            vector_store = FAISS.from_embeddings(\n",
        "                text_embeddings=zip(texts, embs),\n",
        "                embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
        "                metadatas=[d.metadata for d in batch],\n",
        "            )\n",
        "        else:\n",
        "            vector_store.add_embeddings(\n",
        "                text_embeddings=zip(texts, embs),\n",
        "                metadatas=[d.metadata for d in batch],\n",
        "            )\n",
        "\n",
        "        time.sleep(interval)\n",
        "\n",
        "    return vector_store\n",
        "\n",
        "# Usage example:\n",
        "# docs = [Document(page_content=\"Hello\", metadata={}), ...]\n",
        "# vs = build_faiss_from_docs(docs)\n",
        "# vs.save_local(\"faiss_index\")\n"
      ],
      "metadata": {
        "id": "0ckP-nK_JzrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ollama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jl0_Jvv_RoE",
        "outputId": "9c9f37f5-d4ab-466b-a064-354200949d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ollama\n",
            "  Downloading ollama-0.5.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: httpx>=0.27 in /usr/local/lib/python3.11/dist-packages (from ollama) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.11/dist-packages (from ollama) (2.11.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27->ollama) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27->ollama) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27->ollama) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27->ollama) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->ollama) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->ollama) (4.14.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->ollama) (0.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n",
            "Downloading ollama-0.5.1-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: ollama\n",
            "Successfully installed ollama-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ollama\n",
        "\n",
        "response = ollama.embeddings(\n",
        "    model='nomic-embed-text',\n",
        "    prompt='Nom Nom Nom'\n",
        ")\n",
        "\n",
        "embedding = response['embedding']\n"
      ],
      "metadata": {
        "id": "6XK5ha5kJ-vQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdTP7m32O8Cs",
        "outputId": "e44dd72c-6896-4f9c-dead-3e2711d291a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import OllamaEmbeddings"
      ],
      "metadata": {
        "id": "5sQJAKsgPguJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = OllamaEmbeddings(model=\"nomic-embed-text\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOiQ11bhB2dx",
        "outputId": "6ce55eae-7d53-4e14-9502-051d0b7fdb90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-6-1934888258.py:1: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
            "  embedding_model = OllamaEmbeddings(model=\"nomic-embed-text\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store = FAISS.from_documents(chunks, embedding_model)\n"
      ],
      "metadata": {
        "id": "nglJ0u6GB46d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OG7z_hypB7al",
        "outputId": "a6043cac-73cc-4b91-f411-e10b16e5100a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.vectorstores.faiss.FAISS at 0x79e1c80526d0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store.save_local(\"./\", index_name=\"vs1\")"
      ],
      "metadata": {
        "id": "Xp0DPYPfDdeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store = FAISS.load_local(\"./\", embeddings=embedding_model, index_name=\"vs1\", allow_dangerous_deserialization=True)"
      ],
      "metadata": {
        "id": "KOHzjg6SOYWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2tAKgbqPy2h",
        "outputId": "03e45ca7-b427-40c5-abc7-1dff94bf0369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  transcript.txt  vs1.faiss\tvs1.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store.index_to_docstore_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZjbQZ9jDpY5",
        "outputId": "b02d8559-4168-4846-bfdd-13ce9b0f433a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '51fa834c-a177-4f7c-ab77-304081a6357f',\n",
              " 1: 'f70d3ef3-1433-48a9-9f54-7ca222cdd250',\n",
              " 2: '0877cdd8-2441-458d-b9b5-fa1c1711fc42',\n",
              " 3: '122a4e51-a73e-421b-a1b7-ba056a836d3d',\n",
              " 4: 'aceb4ed1-1b91-4e92-b4d8-245806301180',\n",
              " 5: '6e50a7d0-92f9-4b14-9b28-a13d8464a5dc',\n",
              " 6: 'b5876821-3791-4a6b-b606-56687f9cece7',\n",
              " 7: 'bf9f3fed-aa42-49e6-ac27-96fe0de4fc83',\n",
              " 8: '69764df4-94a6-40b5-8830-3d2624c75778',\n",
              " 9: 'c39634cd-f875-4ff7-8da9-5cc2a8d04c54',\n",
              " 10: '0a59ebca-5cea-4828-a5f6-d6b9c592abe1',\n",
              " 11: '147a4719-573d-4254-911f-e2e120208048',\n",
              " 12: '7fd1c397-2168-45bc-923c-d0489df05fcb',\n",
              " 13: '5a2ba799-9116-4e30-b959-03e022a927ac',\n",
              " 14: 'abfe6319-553d-4e29-bafc-fdb36459c820',\n",
              " 15: 'fb322225-8eb7-46af-9541-5ae555ea78b1',\n",
              " 16: 'eaa6ef23-d4b1-433b-b8c4-83315e7727a8',\n",
              " 17: 'af8c02cb-ad40-4c09-9b6c-87e2d0e16e49',\n",
              " 18: '776bae15-b5cf-42d8-9ba1-07eaf26b604d',\n",
              " 19: '0f310932-2104-40f7-90bb-0f8cd64b18c1',\n",
              " 20: 'fe379ad2-f7b2-409a-8d7a-bb80163ad926',\n",
              " 21: '24cb4582-52d2-4397-af8d-9fd99300e569',\n",
              " 22: '3dffb772-f375-49cb-a067-4a8d30400197',\n",
              " 23: '24cd9007-71e8-4dc2-8bbe-9a282737ebcd',\n",
              " 24: '452b004e-5286-4567-b113-2316f5443fed',\n",
              " 25: 'ee23c9cd-c7b0-40b2-b2ea-64564f90a959',\n",
              " 26: '2aeb8f5e-229d-48b7-a0ad-b7bd0a6e5ac1',\n",
              " 27: '46981918-3a34-4c81-a21f-8865e4fe6f34',\n",
              " 28: 'ed4e0156-f879-432c-9465-73f644976a48',\n",
              " 29: 'd9066c2b-42df-42e2-b297-e31ec24916d1',\n",
              " 30: 'd4be0310-67d2-4b3d-831d-c8f0feaf68fa',\n",
              " 31: '4638bed7-e6ff-4452-b755-9f281b317ba2',\n",
              " 32: '1c464710-45d9-4afb-b960-e09bf45d24a4',\n",
              " 33: '9a7bf749-e242-465a-b107-157502b5ae41',\n",
              " 34: '750ad1c9-e16b-4891-9781-258b3e508edc',\n",
              " 35: '0a631a8c-4007-40ce-806d-0bd541953717',\n",
              " 36: '3b1bc085-9617-4b35-abb1-85b784abb52e',\n",
              " 37: '4a1219ae-5012-4c58-95ff-53440bfcca34',\n",
              " 38: '42c55b0b-7a16-46b1-9a84-0387bf637a39',\n",
              " 39: '50416ddc-c327-4b56-b3b5-704b86ae9c0f',\n",
              " 40: 'f56e1efb-4dea-48ef-a899-2ccc52abe050',\n",
              " 41: '16dd2cd3-a646-45d0-ac63-322daee5aefa',\n",
              " 42: '6bab0885-0c5d-422f-a5d8-834eb900efda',\n",
              " 43: 'b2235ab8-c48f-40d1-942f-7625672415b0',\n",
              " 44: '71abf649-27f5-435d-9071-4378153a7c78',\n",
              " 45: '1e262d42-0c96-4e71-9e8a-ff3997f106f0',\n",
              " 46: '7c632f0a-d97b-4325-9945-125c6193f0e6',\n",
              " 47: 'f6342709-b44c-4e1f-8334-0dd1bcf3764b',\n",
              " 48: 'c4a181d1-2f24-4d69-8b9f-3f76fc817c6b',\n",
              " 49: 'e779728f-f89d-4e9b-95e1-21e7e5bf5b9a',\n",
              " 50: '9f601295-9ea3-4376-bbb5-a3d0e6df9fd1',\n",
              " 51: '44b27506-45f0-41ab-ad44-9fd273d1edf1',\n",
              " 52: 'd8c04bcb-2f9b-4f31-82e7-c3a19a0ed0bd',\n",
              " 53: '8b8d85ec-9a9f-4dee-807b-7eb29764ab75',\n",
              " 54: 'bafaad72-a24d-4eef-9327-16235414fc2a',\n",
              " 55: '902b2dbd-096b-4daf-82ea-4a3a6282a561',\n",
              " 56: 'ccb04296-b317-4206-b7e7-926ea84a61d9',\n",
              " 57: 'e6011478-e775-456d-b2ae-ed7696ae62ac',\n",
              " 58: 'd1318a25-8377-4f0f-bede-197e6f804a87',\n",
              " 59: '31b624f6-1e65-4d0f-ba9c-34a22d029a03',\n",
              " 60: '6d2c4f9d-3bc6-4362-96a2-42980db702ef',\n",
              " 61: '1d328c06-0c01-4f82-93fc-5144b423de22',\n",
              " 62: '9b81061f-cfe5-41d9-91cb-b79cef40d746',\n",
              " 63: '51df32e2-b062-462d-8e36-7ad3c0847a3f',\n",
              " 64: '3011c994-99cd-407d-a78d-04b63c5b8dcf',\n",
              " 65: 'a4a69f54-633f-422f-b524-01c140a727dc',\n",
              " 66: '4581e90b-6462-4e6a-a0d6-3560ee92546d',\n",
              " 67: 'ee65a47a-34b8-491e-b707-628fcf175e83',\n",
              " 68: 'b90fc8b1-b702-45dd-970e-aecc7c063fa5',\n",
              " 69: '5684caf1-42d8-44c0-af47-646ecb43af96',\n",
              " 70: 'f5080358-131c-496f-bee9-a3072e922a97',\n",
              " 71: 'ba08a72c-6840-46a9-8527-65ad1b5a8e2a',\n",
              " 72: '8e99d1a1-115d-44c1-996d-151a335f97fb',\n",
              " 73: '79e077af-777a-4e8b-bfa0-dc9783237ac4',\n",
              " 74: '3b8c4f2a-e7f0-4851-aa9a-10efb30f567e',\n",
              " 75: '9ef04c83-1b7f-46c9-93c4-b82ad9b91286',\n",
              " 76: '182aa003-c5ad-433c-9d66-d5d16dbd124e',\n",
              " 77: '5a6b1e9f-fbec-4342-b111-3eae17ea9d94',\n",
              " 78: 'fcfb63a2-0e18-4aeb-89b1-30e961270ddd',\n",
              " 79: '306619b0-065f-42a9-8315-2fd5398ad4b1',\n",
              " 80: '6e4c762c-bb47-44a6-9970-8da5be6e60e2',\n",
              " 81: 'd7a4c893-3d3d-4141-8f28-7ef094a0ee86',\n",
              " 82: '8818ca8d-b6b9-4f6d-8a4e-0ec69bac6505',\n",
              " 83: 'a5304463-e16d-44df-9bd9-3fb354f3a6fa',\n",
              " 84: 'd8973cf1-cae9-4a6e-8125-ca2952973573',\n",
              " 85: '2b9b03d0-f4c8-4b4e-b150-6472c2c513a4',\n",
              " 86: 'e0700e64-ae08-40a4-b9ec-938b0af1e0b9',\n",
              " 87: 'df76a6e6-7035-4f4f-890c-05e2911d3597',\n",
              " 88: '0aac0516-1757-45ec-a2c6-bc38775fa4cb',\n",
              " 89: 'c3437f18-0bac-447b-a488-7ca635613638',\n",
              " 90: '015febd8-eff2-4c75-8486-456f00078bbd',\n",
              " 91: 'fe8136f0-c557-46d1-9d1e-81222c15ed47',\n",
              " 92: '94abbd16-b23e-4e23-8a21-12ad4f5fc73a',\n",
              " 93: '8951cc64-d851-4a27-b222-9bee0fcfd54c',\n",
              " 94: '95fab831-0907-40b2-a8f4-810f5a6dd6f5',\n",
              " 95: '5b4fd5b6-35d9-4a20-95ad-38bfe1149cbd',\n",
              " 96: 'cc99189f-8c57-41e1-9cf5-495b92aba03c',\n",
              " 97: '5329c595-4b72-4f17-9a28-5bb0acce4ba6',\n",
              " 98: '5afb3b85-ec45-46fa-9664-5caf90a2ea42',\n",
              " 99: 'd6695e34-2033-455d-903c-488188ef2f0b',\n",
              " 100: 'b19cd74c-7479-47cc-bed7-862864832d23',\n",
              " 101: 'de419e16-4e4f-432b-961e-d2b794147553',\n",
              " 102: 'd363fca9-9e70-4664-bac1-4a3439201135',\n",
              " 103: '734683c7-572b-4f36-b247-2a71ee4ae546',\n",
              " 104: '5cdad928-bcd2-4004-93f2-28576a5ecf0f',\n",
              " 105: '92b3aef0-3c5c-463c-8848-41f725fd82fd',\n",
              " 106: '4f1da384-3282-4d34-af67-bfbbbb51b10e',\n",
              " 107: 'c0675ff9-07c9-4b01-93eb-647077ae3c5c',\n",
              " 108: '6bb8945c-b275-4a2c-abb4-d338454db931',\n",
              " 109: '81640823-65d1-4f36-97aa-ed4d8c4b0e6e',\n",
              " 110: 'ad7ee18c-307c-47fe-90ec-79a837c94f80',\n",
              " 111: '3396a543-30b9-42a4-a918-2e3196a28ac1',\n",
              " 112: '8f6273a8-eaac-45df-a863-539e8f9378d9',\n",
              " 113: '0f23df8f-0f14-44db-be95-1cb2310fd99e',\n",
              " 114: '44cfe1c5-876e-4a4c-813f-d95821d0a11e',\n",
              " 115: 'acc8f533-fcfd-4823-a46f-29375d6493f3',\n",
              " 116: 'df79f090-929d-4ade-9eaa-8bff3d09733a',\n",
              " 117: 'd7bc5733-c592-42ec-8243-21cfff628b05',\n",
              " 118: '2dbe02b4-bfbe-415a-8dee-b6dc8d701982',\n",
              " 119: 'eb767702-228a-492b-82f1-5980b07b9af2',\n",
              " 120: '1ed3c3b8-9c29-40c1-abb2-a20716d62147',\n",
              " 121: 'be374568-aa31-4c9c-b323-4ed4bf370d5e',\n",
              " 122: '012effda-c3ba-451a-96a8-56dc981b2780',\n",
              " 123: 'adbfbee0-1830-412b-afd2-c3a5ff377e09',\n",
              " 124: '8375162b-51b7-46cf-9354-c811d351d18b',\n",
              " 125: 'fae5265f-65f3-4d25-bc85-72083fe6453d',\n",
              " 126: '76f24fdb-3d6b-4b84-b95e-1bfdcef8bcaf',\n",
              " 127: '7d74fb81-6706-492f-8a0d-72cc25678bc6',\n",
              " 128: 'b19faa7b-f938-479f-a1fc-a2763dad0db6',\n",
              " 129: '0708d537-376d-495e-b8c2-0164a17da066',\n",
              " 130: '452463c0-ab44-48c5-9d64-a1d789274a9d',\n",
              " 131: '5454a9cc-8347-4dac-a1b0-8130ba7d1b2c',\n",
              " 132: '80bfc6ec-c138-4380-b413-a7f11e7a3c8f',\n",
              " 133: '94b2f43a-a83b-4136-95ae-38c91c2ff648',\n",
              " 134: 'b8c0d142-6dee-46f1-a056-089d54f2918a',\n",
              " 135: '689a235d-743d-441f-bcfc-63f94cb1b52e',\n",
              " 136: '251a76d6-4d56-438c-b3f2-b3911c7b5728',\n",
              " 137: '87af95a7-6b6b-489f-a48d-1b52678ec49a',\n",
              " 138: '35f53520-36b2-46d0-a233-6750b01cf69c',\n",
              " 139: '2ee8630a-b867-4899-b28f-5681785ffabe',\n",
              " 140: '654d4bd4-4dfe-405a-ac7e-58411682b5ca',\n",
              " 141: 'c40e662e-4883-43ae-8cca-e4994d4edd90',\n",
              " 142: 'b220da60-d736-4a3f-aaac-54a6fde39f93',\n",
              " 143: '72f32413-4f3a-45fa-8ff1-57da7020dd83',\n",
              " 144: 'fa7cc5d9-71f2-4314-9cba-8b859f20236a',\n",
              " 145: '4d9489cd-d674-40d8-8f94-08800204b7f8',\n",
              " 146: '7f711eb1-991e-4ae6-98b6-ba48672f6adf',\n",
              " 147: '54adfa8b-215a-4c51-afd2-e84940b198f0',\n",
              " 148: '5f2d9a86-ae7d-4bd2-ae74-75fde7b51d5b',\n",
              " 149: 'a3d1734f-e715-4065-a023-0202e4690167',\n",
              " 150: 'def63481-7ded-4eb4-98a4-7b124a774f8a',\n",
              " 151: 'ba0d9d7a-e181-42ab-91a3-74827bdf8218',\n",
              " 152: '6aaf721e-e033-40f2-8e2b-e52f2f3a0469',\n",
              " 153: '01dac5ec-d193-483a-8b6b-fb492688e53b',\n",
              " 154: '0249e600-8f12-435e-a27d-c3519a908fe0',\n",
              " 155: '6901cd1c-538d-4e55-b9aa-a55c6a50e904',\n",
              " 156: '02b59e67-0cb3-47bd-acac-bc3866b9ead2',\n",
              " 157: '63ba0d4f-bcb8-485e-8fd6-a855687efca3',\n",
              " 158: '4a902e7b-a123-48fd-868d-907d2bc571cc',\n",
              " 159: '46243020-3689-46cf-a879-549f0859797d',\n",
              " 160: '544d9aec-8fa8-4609-9221-8bcfd49814c0',\n",
              " 161: 'cbe14ef7-28aa-4329-b656-9bf1891c0d10',\n",
              " 162: '1730dea3-b65b-4558-9773-8d97ce9a3fdb',\n",
              " 163: '9c6e2b2e-e9c1-47f0-951d-b86f059c8185',\n",
              " 164: '8892a55f-8ab4-4780-a79e-7279881b3c40',\n",
              " 165: 'e6b53e96-cc7c-4ed0-98c8-4ebc562d1843',\n",
              " 166: '6a66a0fa-3316-445e-904c-e1fd8eb7362a',\n",
              " 167: 'c63e084d-5331-410e-b6ad-c85ffa949e56'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store.get_by_ids(['c63e084d-5331-410e-b6ad-c85ffa949e56'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4ddvjogD_uN",
        "outputId": "61f36918-9ee4-4d97-b501-bf4ac09c4f46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='c63e084d-5331-410e-b6ad-c85ffa949e56', metadata={}, page_content='demas establish to support this podcast please check out our sponsors in the description and now let me leave you with some words from edskar dykstra computer science is no more about computers than astronomy is about telescopes thank you for listening and hope to see you next time')]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieval"
      ],
      "metadata": {
        "id": "VQKnfFhAERMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_store.as_retriever(search_type = 'similarity', search_kwargs = {'k' : 4})"
      ],
      "metadata": {
        "id": "xmiY_bn5EIU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.invoke('What is Deepmind?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cehZRhPWEwt9",
        "outputId": "90291e2d-649e-4e67-d8b0-fb2a684f2c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='3011c994-99cd-407d-a78d-04b63c5b8dcf', metadata={}, page_content=\"and how it works this is tough to uh ask you this question because you probably will say it's everything but let's let's try let's try to think to this because you're in a very interesting position where deepmind is the place of some of the most uh brilliant ideas in the history of ai but it's also a place of brilliant engineering so how much of solving intelligence this big goal for deepmind how much of it is science how much is engineering so how much is the algorithms how much is the data how much is the hardware compute infrastructure how much is it the software computer infrastructure yeah um what else is there how much is the human infrastructure and like just the humans interact in certain kinds of ways in all the space of all those ideas how much does maybe like philosophy how much what's the key if um uh if if you were to sort of look back like if we go forward 200 years look back what was the key thing that solved intelligence is that ideas i think it's a combination first\"),\n",
              " Document(id='ee65a47a-34b8-491e-b707-628fcf175e83', metadata={}, page_content='i used to discuss um uh uh what were the sort of founding tenets of deep mind and it was very various things one was um algorithmic advances so deep learning you know jeff hinton and cohen just had just sort of invented that in academia but no one in industry knew about it uh we love reinforcement learning we thought that could be scaled up but also understanding about the human brain had advanced um quite a lot uh in the decade prior with fmri machines and other things so we could get some good hints about architectures and algorithms and and sort of um representations maybe that the brain uses so as at a systems level not at a implementation level um and then the other big things were compute and gpus right so we could see a compute was going to be really useful and it got to a place where it became commoditized mostly through the games industry and and that could be taken advantage of and then the final thing was also mathematical and theoretical definitions of intelligence so'),\n",
              " Document(id='79e077af-777a-4e8b-bfa0-dc9783237ac4', metadata={}, page_content=\"ambitious as trying to solve intelligence and you're you're you know it's blue sky research no one knows how to do it you you you need to use any evidence or any source of information you can to help guide you in the right direction or give you confidence you're going in the right direction so so that that was one reason we pushed so hard on that and that's and just going back to your early question about organization the other big thing that i think we innovated with at deepmind to encourage invention and and uh and innovation was the multi-disciplinary organization we built and we still have today so deepmind originally was a confluence of the of the most cutting-edge knowledge in neuroscience with machine learning engineering and mathematics right and and gaming and then since then we built that out even further so we have philosophers here and and uh by you know ethicists but also other types of scientists physicists and so on um and that's what brings together i tried to build a\"),\n",
              " Document(id='80bfc6ec-c138-4380-b413-a7f11e7a3c8f', metadata={}, page_content=\"of deep mind just as a human being let me ask you about this one particular anecdotal evidence of the google engineer who made a comment or believed that there's some aspect of a language model the lambda language model that exhibited sentience so you said you believe there might be a responsibility to build systems that are not essential and this experience of a particular engineer i think i'd love to get your general opinion on this kind of thing but i think it will happen more and more and more which uh not when engineers but when people out there that don't have an engineering background start interacting with increasingly intelligent systems we anthropomorphize them they they start to have deep impactful um interactions with us in a way that we miss them yeah when they're gone and we sure feel like they're living entities self-aware entities and maybe even we project sentience onto them so what what's your thought about this particular uh system was is uh have you ever met a\")]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever ## INPUT: Query, RESULT: List of Documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NqfvI9DE1-2",
        "outputId": "9a0b529a-8557-41dd-d539-f8355efadff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7ec648c0f5d0>, search_kwargs={'k': 4})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cwzs9soSKoGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Augmentation"
      ],
      "metadata": {
        "id": "yrwM2tDcFC6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_google_genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQ1TpH5PKTuo",
        "outputId": "59c78a10-c998-48a3-b23d-094ba5eda6ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_google_genai in /usr/local/lib/python3.11/dist-packages (2.1.6)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (0.6.18)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (0.3.67)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (2.11.7)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.29.5)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (0.4.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (4.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.73.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GEMINI_KEY')"
      ],
      "metadata": {
        "id": "xunE_LeEQ0WV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.9)\n",
        "prompt = \"Explain what ChatGoogleGenerativeAI function do in langchain_google_genai.\"\n",
        "response = llm.invoke(prompt)\n",
        "print(response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgZgNkcrKhAB",
        "outputId": "40927b8c-4b1e-48bb-910c-28c70d81c391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The `ChatGoogleGenerativeAI` class in `langchain_google_genai` is a Langchain integration for interacting with Google's Generative AI models, specifically those designed for conversational (chat) interactions.  It's a wrapper around the Google Generative AI SDK that makes it easy to build conversational AI applications within the Langchain ecosystem.\n",
            "\n",
            "Here's a breakdown of what it does and its key features:\n",
            "\n",
            "**Core Functionality:**\n",
            "\n",
            "* **Connects to Google's Chat Models:** The primary function is to establish a connection to Google's Generative AI API, allowing you to send chat-based prompts and receive responses from models like Gemini Pro. It handles the authentication and communication with the Google Cloud backend.\n",
            "\n",
            "* **Chat-Focused Interface:** Unlike models designed for single-shot text generation, `ChatGoogleGenerativeAI` is optimized for multi-turn conversations. It maintains a conversation state (through the underlying Gemini API) and can understand context from previous turns.  This is crucial for building chatbots or interactive assistants.\n",
            "\n",
            "* **Langchain Integration:**  It's built as a Langchain `ChatModel`, meaning it adheres to the Langchain interface for chat models.  This makes it easy to plug `ChatGoogleGenerativeAI` into Langchain chains, agents, and other components.  You can seamlessly combine it with other Langchain tools for tasks like:\n",
            "    * **Data Retrieval:** Integrating with vector databases to ground the model in real-world information.\n",
            "    * **Tool Use:**  Enabling the model to call external APIs and tools to perform actions.\n",
            "    * **Memory Management:**  Using Langchain's memory components to store and retrieve past conversation history.\n",
            "\n",
            "* **Message Handling:** It accepts a list of `BaseMessage` objects as input. Langchain defines various message types, such as:\n",
            "    * `HumanMessage`: Represents a message from the user.\n",
            "    * `AIMessage`: Represents a response from the AI model.\n",
            "    * `SystemMessage`: Provides instructions or context to the model at the start of the conversation.\n",
            "    * `FunctionMessage`:  Represents the output of a tool/function call.\n",
            "\n",
            "* **Response Parsing:**  It parses the response from the Google Generative AI API and returns an `AIMessage` object, which can then be easily processed by other Langchain components.  It typically extracts the text content of the response.\n",
            "\n",
            "* **Configuration Options:** The class provides options for configuring the model's behavior, such as:\n",
            "    * `model_name`:  Specifies the name of the Generative AI model to use (e.g., \"gemini-pro\").\n",
            "    * `temperature`: Controls the randomness of the model's output.  Higher values lead to more creative but potentially less coherent responses.\n",
            "    * `top_p`:  Controls the sampling of the most likely tokens.\n",
            "    * `top_k`:  Limits the number of tokens considered for sampling.\n",
            "    * `max_output_tokens`:  Sets a maximum length for the model's response.\n",
            "    * `generation_config`:  Lets you specify a `GenerationConfig` object to configure various generation parameters.\n",
            "    * `safety_settings`:  Allows you to configure safety filters to control the types of responses the model generates.\n",
            "    * `convert_system_message_to_human`:  (Boolean) Determines if the system message should be converted to a human message.\n",
            "\n",
            "**Example Usage:**\n",
            "\n",
            "```python\n",
            "from langchain_google_genai import ChatGoogleGenerativeAI\n",
            "from langchain_core.messages import HumanMessage, SystemMessage\n",
            "\n",
            "# Initialize the chat model\n",
            "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.7)\n",
            "\n",
            "# Create a conversation\n",
            "messages = [\n",
            "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
            "    HumanMessage(content=\"What is the capital of France?\")\n",
            "]\n",
            "\n",
            "# Get the model's response\n",
            "response = llm.invoke(messages)\n",
            "\n",
            "# Print the response\n",
            "print(response.content)  # Output: Paris\n",
            "```\n",
            "\n",
            "**Key Benefits:**\n",
            "\n",
            "* **Simplified API Interaction:**  Abstracts away the complexities of directly interacting with the Google Generative AI API.\n",
            "* **Seamless Langchain Integration:**  Fits naturally into the Langchain ecosystem, making it easy to build complex AI applications.\n",
            "* **Conversational Focus:**  Designed specifically for chat-based applications, providing tools for managing conversation state and context.\n",
            "* **Configuration Options:**  Offers a range of configuration options to fine-tune the model's behavior.\n",
            "\n",
            "In essence, `ChatGoogleGenerativeAI` is a bridge between Langchain and Google's powerful Generative AI chat models, allowing developers to quickly and easily build sophisticated conversational AI applications.  It handles the low-level API details, letting you focus on the logic and flow of your application.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    template = \"\"\"\n",
        "      You are a helpful assistant.\n",
        "      Answer ONLY from the provided transcript context.\n",
        "      If the context is insufficient, just say you don't know.\n",
        "\n",
        "      {context}\n",
        "      Question: {question}\n",
        "    \"\"\",\n",
        "    input_variables = ['context', 'question']\n",
        ")"
      ],
      "metadata": {
        "id": "n2dWjFIRLibH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"is the topic of aliens discussed in the video? If yes, then what was discussed?\""
      ],
      "metadata": {
        "id": "ZIdxMuxcE7bZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_docs = retriever.invoke(question)"
      ],
      "metadata": {
        "id": "ZDDgVvQLMC5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGqoJ-d7MX1C",
        "outputId": "66f44c28-2b99-49ec-9ba0-438fb7bd16bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='1ed3c3b8-9c29-40c1-abb2-a20716d62147', metadata={}, page_content=\"thoughts it could be some interactions with our mind that we think are originating from us is actually something that uh is coming from other life forms elsewhere consciousness itself might be that it could be but i don't see any sensible argument to the why why would all of the alien species be using this way yes some of them will be more primitive they would be close to our level you know there would there should be a whole sort of normal distribution of these things right some would be aggressive some would be you know curious others would be very stoical and philosophical because you know maybe they're a million years older than us but it's not it shouldn't be like what i mean one one alien civilization might be like that communicating thoughts and others but i don't see why you know potentially the hundreds there should be would be uniform in this way right it could be a violent dictatorship that the the people the alien civilizations that uh become successful become um [Music]\"),\n",
              " Document(id='eb767702-228a-492b-82f1-5980b07b9af2', metadata={}, page_content=\"something there's something more deeper underlying it maybe computational now if we were in a if we were in a sort of safari park and everything we were seeing was a hologram and it was projected by the aliens or whatever that to me is not much different than thinking we're inside of another universe because we still can't see true reality right i mean there's there's other explanations it could be that the way they're communicating is just fundamentally different that we're too dumb to understand the much better methods of communication they have it could be i mean i mean it's silly to say but our own thoughts could be the methods by which they're communicating like the place from which our ideas writers talk about this like the muse yeah it sounds like very kind of uh wild but it could be thoughts it could be some interactions with our mind that we think are originating from us is actually something that uh is coming from other life forms elsewhere consciousness itself might be that\"),\n",
              " Document(id='d7bc5733-c592-42ec-8243-21cfff628b05', metadata={}, page_content=\"space age we should have heard a cacophony of voices we should have joined that cacophony of voices and what we did we opened our ears and we heard nothing and many people who argue that there are aliens would say well we haven't really done exhaustive search yet and maybe we're looking in the wrong bands and and we've got the wrong devices and we wouldn't notice what an alien form was like to be so different to what we're used to but you know i'm not i don't really buy that that it shouldn't be as difficult as that like we i think we've searched enough there should be if it were everywhere if it was it should be everywhere we should see dyson's fears being put up sun's blinking in and out you know there should be a lot of evidence for those things and then there are other people argue well the sort of safari view of like well we're a primitive species still because we're not space faring yet and and and we're you know there's some kind of globe like universal rule not to interfere\"),\n",
              " Document(id='0f23df8f-0f14-44db-be95-1cb2310fd99e', metadata={}, page_content=\"other option of course we could enhance ourselves and and without devices we we are already sort of symbiotic with our compute devices right with our phones and other things and you know this stuff like neural link and etc that could be could could advance that further um so i think there's lots of lots of really amazing possibilities uh that i could foresee from here well let me ask you some wild questions so out there looking for friends do you think there's a lot of alien civilizations out there so i guess this also goes back to your origin of life question too because i think that that's key um my personal opinion looking at all this and and you know it's one of my hobbies physics i guess so so i i you know it's something i think about a lot and talk to a lot of experts on and and and read a lot of books on and i think my feeling currently is that that we are alone i think that's the most likely scenario given what what evidence we have so um and the reasoning is i think that you\")]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)"
      ],
      "metadata": {
        "id": "UYuYsVtlMGUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_prompt = prompt.invoke({'context': context_text, 'question': question})"
      ],
      "metadata": {
        "id": "oBqbTXM9MNT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generation"
      ],
      "metadata": {
        "id": "VgYZOPxmMf8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer = llm.invoke(final_prompt)"
      ],
      "metadata": {
        "id": "taG3mn-yMehb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(answer.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGI9kzORRoKr",
        "outputId": "6f1139de-d8af-4492-a902-7ab82ffc1f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes, the topic of aliens is discussed in the video.\n",
            "The discussion includes:\n",
            "\n",
            "*   The possibility of alien civilizations communicating through our thoughts or consciousness.\n",
            "*   The lack of evidence for alien civilizations, such as Dyson spheres or other signs of advanced technology.\n",
            "*   The idea that there may be a universal rule not to interfere with primitive species like humans.\n",
            "*   The possibility that we are alone in the universe.\n",
            "*   The possibility that the way aliens communicate is fundamentally different and we are too dumb to understand.\n",
            "*   The possibility of safari view, where we are a primitive species and there's some kind of universal rule not to interfere.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a Chain"
      ],
      "metadata": {
        "id": "lCM_6f1sR3bN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## call invoke once, and the entire pipeline runs\n",
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda"
      ],
      "metadata": {
        "id": "UzMdicDrRroJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(retrieved_docs):\n",
        "  context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "  return context_text"
      ],
      "metadata": {
        "id": "VbsA5MY4S1sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parallel_chain = RunnableParallel( ## Dictionary as input\n",
        "    {\n",
        "        'context': retriever | RunnableLambda(format_docs), ## output is context string\n",
        "        'question': RunnablePassthrough()\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "uFhcykVrTA3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parallel_chain.invoke('who is Demis?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZzU5jY1TfM8",
        "outputId": "2d9ae38c-d637-4cf3-ca55-79d8cc77072f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context': \"demas establish to support this podcast please check out our sponsors in the description and now let me leave you with some words from edskar dykstra computer science is no more about computers than astronomy is about telescopes thank you for listening and hope to see you next time\\n\\nthe following is a conversation with demus hasabis ceo and co-founder of deepmind a company that has published and builds some of the most incredible artificial intelligence systems in the history of computing including alfred zero that learned all by itself to play the game of gold better than any human in the world and alpha fold two that solved protein folding both tasks considered nearly impossible for a very long time demus is widely considered to be one of the most brilliant and impactful humans in the history of artificial intelligence and science and engineering in general this was truly an honor and a pleasure for me to finally sit down with him for this conversation and i'm sure we will talk many times again in the future this is the lex friedman podcast to support it please check out our sponsors in the description and now dear friends here's demis hassabis let's start with a bit of a personal question am i an ai program you wrote to interview people until i get good enough\\n\\nout our sponsors in the description and now dear friends here's demis hassabis let's start with a bit of a personal question am i an ai program you wrote to interview people until i get good enough to interview you well i'll be impressed if if you were i'd be impressed by myself if you were i don't think we're quite up to that yet but uh maybe you're from the future lex if you did would you tell me is that is that a good thing to tell a language model that's tasked with interviewing that it is in fact um ai maybe we're in a kind of meta turing test uh probably probably it would be a good idea not to tell you so it doesn't change your behavior right this is a kind of heisenberg uncertainty principle situation if i told you you behave differently yeah maybe that's what's happening with us of course this is a benchmark from the future where they replay 2022 as a year before ais were good enough yet and now we want to see is it going to pass exactly if i was such a program would you be\\n\\ndeeper maybe simpler explanation yes of things right than the standard model of physics which we know doesn't work but we still keep adding to so um and and that's how i think the beginning of an explanation would look and it would start encompassing many of the mysteries that we have wondered about for thousands of years like you know consciousness uh life and gravity all of these things yeah giving us a glimpses of explanations for those things yeah well um damas dear one of the special human beings in this giant puzzle of ours and it's a huge honor that you would take a pause from the bigger puzzle to solve this small puzzle of a conversation with me today it's truly an honor and a pleasure thank you thank you i really enjoyed it thanks lex thanks for listening to this conversation with demas establish to support this podcast please check out our sponsors in the description and now let me leave you with some words from edskar dykstra computer science is no more about computers than\",\n",
              " 'question': 'who is Demis?'}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "1OorfmusTolW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_chain = parallel_chain | prompt | llm | parser"
      ],
      "metadata": {
        "id": "eFdtEKF9T5UN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_chain.invoke('Can you summarise the video?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "HnN6Wmg8UL-T",
        "outputId": "87e954e4-a78f-44ba-d7fc-2b2854e6afbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The video discusses the beginning of an explanation that would encompass many mysteries, such as consciousness, life, and gravity. It also touches on testing AI capabilities on a range of tasks to see if it reaches human level or above performance, and the generalizability across multiple tasks.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K5sBWH8VUTVO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}